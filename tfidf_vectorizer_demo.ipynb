{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# TF-IDF Vectorizer Implementation with Python\n", "\n", "In this notebook, we will implement **TF-IDF (Term Frequency - Inverse Document Frequency)** using Python and the `sklearn` library. This technique helps us understand the importance of a word in a document relative to a collection of documents (corpus).\n", "\n", "We will follow these steps:\n", "1. Load the spam dataset\n", "2. Clean and preprocess the text (lowercase, remove stopwords, apply lemmatization)\n", "3. Convert the corpus into TF-IDF vectors\n", "4. Explore n-grams with TF-IDF\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Load the dataset\n", "import pandas as pd\n", "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n", "df.columns = ['label', 'text']\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 2: Text Cleaning and Lemmatization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nltk\n", "import re\n", "import numpy as np\n", "from nltk.corpus import stopwords\n", "from nltk.stem import WordNetLemmatizer\n", "\n", "nltk.download('stopwords')\n", "nltk.download('wordnet')\n", "nltk.download('omw-1.4')\n", "\n", "lemmatizer = WordNetLemmatizer()\n", "corpus = []\n", "\n", "for text in df['text']:\n", "    review = re.sub('[^a-zA-Z]', ' ', text)\n", "    review = review.lower().split()\n", "    review = [lemmatizer.lemmatize(word) for word in review if word not in stopwords.words('english')]\n", "    corpus.append(' '.join(review))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 3: Apply TF-IDF Vectorizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "\n", "tfidf = TfidfVectorizer(max_features=100)\n", "X = tfidf.fit_transform(corpus).toarray()\n", "X[:5]  # Display first 5 vectors"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As you can see, each sentence is converted into a 100-dimensional vector representing TF-IDF scores of top 100 most frequent words in the corpus."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 4: Use TF-IDF with n-grams (bigrams)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tfidf_bigram = TfidfVectorizer(max_features=100, ngram_range=(2, 2))\n", "X_bigram = tfidf_bigram.fit_transform(corpus).toarray()\n", "X_bigram[:5]  # Display first 5 bigram vectors"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### View Vocabulary\n", "You can view the vocabulary used in the TF-IDF representation using the `get_feature_names_out()` method:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tfidf_bigram.get_feature_names_out()[:10]  # Display first 10 bigram features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "- We implemented TF-IDF using sklearn\n", "- Preprocessed the text using lemmatization\n", "- Explored both word-level and bigram-level TF-IDF vectors\n", "\n", "Next step would be to split the data into train/test sets and apply machine learning algorithms!"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}