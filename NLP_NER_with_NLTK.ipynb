{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3eb2ee",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) using NLTK\n",
    "\n",
    "This notebook provides a detailed explanation and demonstration of Named Entity Recognition (NER) using the Natural Language Toolkit (NLTK) in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3aebc",
   "metadata": {},
   "source": [
    "## What is Named Entity Recognition?\n",
    "Named Entity Recognition (NER) is a subtask of information extraction that classifies named entities into predefined categories such as:\n",
    "- Person\n",
    "- Location\n",
    "- Organization\n",
    "- Date/Time\n",
    "- Money\n",
    "- Percentages\n",
    "\n",
    "NER is a crucial component in Natural Language Processing (NLP) applications like information retrieval, question answering, and summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6895404d",
   "metadata": {},
   "source": [
    "## Example Sentence\n",
    "Consider the following sentence:\n",
    "\n",
    "> *\"The Eiffel Tower was built from 1887 to 1889 by French engineer Gustave Eiffel, whose company specialized in building metal frameworks and structures.\"*\n",
    "\n",
    "This sentence contains several named entities:\n",
    "- `Eiffel Tower`: Location or Organization\n",
    "- `1887 to 1889`: Date/Time\n",
    "- `Gustave Eiffel`: Person\n",
    "- `French`: Nationality/Geopolitical Entity (GPE)\n",
    "\n",
    "We'll use NLTK to identify these entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd3d8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5cc3cc",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "We first tokenize the sentence into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49afc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Eiffel',\n",
       " 'Tower',\n",
       " 'was',\n",
       " 'built',\n",
       " 'from',\n",
       " '1887',\n",
       " 'to',\n",
       " '1889',\n",
       " 'by',\n",
       " 'French',\n",
       " 'engineer',\n",
       " 'Gustave',\n",
       " 'Eiffel',\n",
       " ',',\n",
       " 'whose',\n",
       " 'company',\n",
       " 'specialized',\n",
       " 'in',\n",
       " 'building',\n",
       " 'metal',\n",
       " 'frameworks',\n",
       " 'and',\n",
       " 'structures',\n",
       " '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The Eiffel Tower was built from 1887 to 1889 by French engineer Gustave Eiffel, whose company specialized in building metal frameworks and structures.\"\n",
    "tokens = word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3eb39f",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagging\n",
    "Next, we assign parts of speech to each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd5fdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Eiffel', 'NNP'),\n",
       " ('Tower', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('built', 'VBN'),\n",
       " ('from', 'IN'),\n",
       " ('1887', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('1889', 'CD'),\n",
       " ('by', 'IN'),\n",
       " ('French', 'JJ'),\n",
       " ('engineer', 'NN'),\n",
       " ('Gustave', 'NNP'),\n",
       " ('Eiffel', 'NNP'),\n",
       " (',', ','),\n",
       " ('whose', 'WP$'),\n",
       " ('company', 'NN'),\n",
       " ('specialized', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('building', 'NN'),\n",
       " ('metal', 'NN'),\n",
       " ('frameworks', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('structures', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens = pos_tag(tokens)\n",
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59576b3",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "Now we apply NER chunking using `ne_chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6e9642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\vishalrathod/nltk_data', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\nltk_data', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\vishalrathod\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vishalrathod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Check where NLTK is looking for data\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975fca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(r'D:\\nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b336b552",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mmaxent_ne_chunker_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('maxent_ne_chunker_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mchunkers/maxent_ne_chunker_tab/english_ace_binary/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vishalrathod/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vishalrathod\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ne_chunk\n\u001b[1;32m----> 2\u001b[0m named_entities \u001b[38;5;241m=\u001b[39m \u001b[43mne_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtagged_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m named_entities\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\chunk\\__init__.py:190\u001b[0m, in \u001b[0;36mne_chunk\u001b[1;34m(tagged_tokens, binary)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03mUse NLTK's currently recommended named entity chunker to\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03mchunk the given list of tagged tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m--> 190\u001b[0m     chunker \u001b[38;5;241m=\u001b[39m \u001b[43mne_chunker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     chunker \u001b[38;5;241m=\u001b[39m ne_chunker()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\chunk\\__init__.py:174\u001b[0m, in \u001b[0;36mne_chunker\u001b[1;34m(fmt)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mne_chunker\u001b[39m(fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m    Load NLTK's currently recommended named entity chunker.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMaxent_NE_Chunker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\chunk\\named_entity.py:329\u001b[0m, in \u001b[0;36mMaxent_NE_Chunker.__init__\u001b[1;34m(self, fmt)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmt \u001b[38;5;241m=\u001b[39m fmt\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tab_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunkers/maxent_ne_chunker_tab/english_ace_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfmt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_params()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mmaxent_ne_chunker_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('maxent_ne_chunker_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mchunkers/maxent_ne_chunker_tab/english_ace_binary/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vishalrathod/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vishalrathod\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "named_entities = ne_chunk(tagged_tokens, binary=True)\n",
    "named_entities.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0b9b2",
   "metadata": {},
   "source": [
    "## Visualizing Named Entities\n",
    "You can visualize the named entity tree using the `.draw()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f4baa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'named_entities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This will open a pop-up window with the tree visualization (if supported)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnamed_entities\u001b[49m\u001b[38;5;241m.\u001b[39mdraw()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'named_entities' is not defined"
     ]
    }
   ],
   "source": [
    "# This will open a pop-up window with the tree visualization (if supported)\n",
    "named_entities.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578b7a6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We used NLTK to perform Named Entity Recognition on a sample sentence.\n",
    "- Tokenization, POS tagging, and chunking were demonstrated.\n",
    "- Named entities such as persons, locations, and dates were identified.\n",
    "\n",
    "NER is a powerful tool for extracting structured information from unstructured text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
