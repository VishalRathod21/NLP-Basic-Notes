{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Natural Language Processing - N-grams with NLTK and Scikit-learn\n\nIn this notebook, we will implement and understand how to use **N-grams** using **NLTK** and **Scikit-learn** with a Spam Classification problem statement.\n\nWe will:\n- Create Bag of Words\n- Understand vocabulary extraction\n- Use `ngram_range` in `CountVectorizer`\n- Experiment with unigram, bigram, trigram combinations\n- Observe how the feature space changes\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Import required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Sample dataset (SMS spam messages)\ncorpus = [\n    'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.',\n    'U dun say so early hor... U c already then say...',\n    'Nah I don\u2019t think he goes to usf, he lives around here though',\n    'WINNER!! As a valued network customer you have been selected to receivea \u00a3900 prize reward!',\n    'Had your mobile 11 months or more? You are eligible to update to the latest colour mobiles with camera for free!',\n    'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575.',\n    'I\u2018m gonna be home soon and i don\u2018t want to talk about this stuff anymore tonight.',\n    'URGENT! You have won a 1 week FREE membership in our \u00a3100,000 Prize Jackpot!',\n    'I\u2018ve been searching for the right words to thank you for this breather. I promise i won\u2018t take your help for granted again.',\n    'As per your request, your subscription has been renewed.'\n]"}, {"cell_type": "markdown", "metadata": {}, "source": "## Bag of Words Model\nWe'll use `CountVectorizer` to convert the text documents to a matrix of token counts.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Bag of Words with top 100 frequent words\ncv = CountVectorizer(max_features=100)\nX = cv.fit_transform(corpus).toarray()\n\nprint(\"Vocabulary (Top 100 Words):\")\nprint(cv.vocabulary_)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Exploring N-grams with `ngram_range`\n\n### Unigram (1,1)\nOnly single words are considered as features."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Unigram only\ncv = CountVectorizer(max_features=100, ngram_range=(1,1))\nX = cv.fit_transform(corpus).toarray()\nprint(\"Unigram Vocabulary:\")\nprint(cv.vocabulary_)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Unigram + Bigram (1,2)\nCombines both single and two-word combinations."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Unigram and Bigram\ncv = CountVectorizer(max_features=200, ngram_range=(1,2))\nX = cv.fit_transform(corpus).toarray()\nprint(\"Unigram + Bigram Vocabulary:\")\nprint(cv.vocabulary_)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Bigram only (2,2)\nOnly two-word combinations considered as features."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Bigram only\ncv = CountVectorizer(max_features=200, ngram_range=(2,2))\nX = cv.fit_transform(corpus).toarray()\nprint(\"Bigram Vocabulary:\")\nprint(cv.vocabulary_)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Trigram only (3,3)\nOnly three-word combinations considered."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Trigram only\ncv = CountVectorizer(max_features=200, ngram_range=(3,3))\nX = cv.fit_transform(corpus).toarray()\nprint(\"Trigram Vocabulary:\")\nprint(cv.vocabulary_)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Summary\n- Start with `ngram_range=(1,1)` (Unigram).\n- If accuracy is low, try `(1,2)` or `(1,3)`.\n- You can also test `(2,3)` for bigram + trigram only.\n- Adjust `max_features` to get more/less frequent words.\n\nNext step: Explore **TF-IDF** transformation.\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}