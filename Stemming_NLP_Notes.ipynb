{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù NLP Notes: Stemming\n",
    "\n",
    "## üîπ What is Stemming?\n",
    "Stemming is the process of reducing words to their base or root form. For example, the words \"playing\", \"played\", and \"plays\" can all be reduced to the root word \"play\".\n",
    "\n",
    "Stemming is used to:\n",
    "- Normalize words\n",
    "- Improve text matching and information retrieval\n",
    "- Reduce the dimensionality of text data\n",
    "\n",
    "‚ö†Ô∏è Note: The result may not always be a valid English word (e.g., \"studies\" ‚Üí \"studi\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ 1. Porter Stemmer (Most Common)\n",
    "Uses a series of rules to remove common suffixes from words in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ‚Üí python\n",
      "pythoning ‚Üí python\n",
      "pythoned ‚Üí python\n",
      "pythonly ‚Üí pythonli\n",
      "studies ‚Üí studi\n",
      "studying ‚Üí studi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "words = [\"python\", \"pythoning\", \"pythoned\", \"pythonly\", \"studies\", \"studying\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ‚Üí {ps.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ 2. Lancaster Stemmer\n",
    "A more aggressive stemmer compared to Porter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ‚Üí python\n",
      "pythoning ‚Üí python\n",
      "pythoned ‚Üí python\n",
      "pythonly ‚Üí python\n",
      "studies ‚Üí study\n",
      "studying ‚Üí study\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "ls = LancasterStemmer()\n",
    "for word in words:\n",
    "    print(f\"{word} ‚Üí {ls.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ 3. Regexp Stemmer\n",
    "Uses regular expressions to remove specific suffixes from words.\n",
    "\n",
    "You can define your own rules using the `RegexpStemmer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ‚Üí python\n",
      "pythoning ‚Üí python\n",
      "pythoned ‚Üí python\n",
      "pythonly ‚Üí pythonly\n",
      "studies ‚Üí studie\n",
      "studying ‚Üí study\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Remove common suffixes like -ing, -ed, -s\n",
    "regexp_stemmer = RegexpStemmer('ing$|ed$|s$', min=4)\n",
    "for word in words:\n",
    "    print(f\"{word} ‚Üí {regexp_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìò RegexpStemmer Class Explanation:\n",
    "`RegexpStemmer` works by removing suffixes that match a regular expression.\n",
    "\n",
    "- **Syntax:** `RegexpStemmer(pattern, min=0)`\n",
    "    - `pattern`: A regex pattern to match suffixes\n",
    "    - `min`: Minimum length of the remaining stem\n",
    "\n",
    "**Example:** To remove -ing, -ly, or -ed:\n",
    "```python\n",
    "RegexpStemmer(\"ing$|ly$|ed$\", min=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ 4. Snowball Stemmer\n",
    "Supports multiple languages and is more accurate than Porter for some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ‚Üí python\n",
      "pythoning ‚Üí python\n",
      "pythoned ‚Üí python\n",
      "pythonly ‚Üí python\n",
      "studies ‚Üí studi\n",
      "studying ‚Üí studi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball = SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "    print(f\"{word} ‚Üí {snowball.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67799b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"pythoned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Summary Comparison Table\n",
    "\n",
    "| Word       | Porter | Lancaster | Regexp | Snowball |\n",
    "|------------|--------|-----------|--------|----------|\n",
    "| studies    | studi  | study     | studi  | studi    |\n",
    "| studying   | studi  | study     | study  | studi    |\n",
    "| pythoned   | python | python    | python | python   |\n",
    "| pythoning  | python | python    | python | python   |\n",
    "| pythonly   | python | python    | python | python   |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
